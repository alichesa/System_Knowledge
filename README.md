# System_Knowledge
- 在X86架构中一般有四个不同的特权级，R0 ~ R3，R0是内核态，R3是用户态，R1和R2一般是驱动程序。用户态一般使用系统调用（Syscall -- read write open 等内核函数）与内核进行交互，一般态的切换中会触发中断。系统调用一般会比普通的函数运行慢，因为它设计上下文的切换，一般是100-200个cpu周期。具体流程是：用户程序调用write() → 触发0x80中断 → CPU保存用户态寄存器 → 切换至内核栈 → 执行sys_write() → 返回用户态前恢复现场

- 用户态申请内存的流程是：应用程序调用malloc → brk/mmap触发 → 内核管理物理内存，具体实现流程 -- 检测申请内存 → 调用相应的函数 → 在进程空间创建虚拟内存区域 → 建立页表映射 → 返回虚拟地址 → 程序首次访问内存触发缺页异常，此时内核分配实际物理内存。其中mmap是大块内存（>256kb）另外一个是小内存。mmap与brk的区别就是mmap使用free会立即释放内存，而brk不会立即释放，只是先将内存标记为缓冲区。频繁使用mmap会不断触发缺页中断，这就导致上下文切换十分频繁；频繁使用brk会导致页的碎片化很严重。brk的碎片是内部碎片，主要是虚假释放的碎片，mmap的碎片是外部碎片，就是一段一段不连续是内存碎片

- malloc先是分配虚拟内存，当程序访问的时候就会产生缺页中断，此时就会访问实际的物理内存，若此时的物理内存足够那就正常运行，若此时的物理内存不够那就会有后台内存回收（在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行）和直接内存回收（如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行）两个方式，若还是不行的话则会启动OOM Killer杀死较高内存的进程，直至内存满足

- 在 32 位操作系统、4GB 物理内存的机器上，申请 8GB 内存肯定会报错，因为最大也就只能到4GB，而在 64 位操作系统、4GB 物理内存的机器上，申请 8GB 内存能成功，若开启了Swap则程序运行的时候也不会出错

- 进程是系统资源分配的最小单元，每个进程都有独立的地址空间、堆栈、文件描述符等。线程是程序调度的最小单元，多个线程之间共享内存空间、全局变量等。进程创建的开销是比较大的，因为需要分配独立的资源，需要系统内核负责，也会涉及到上下文的切换，并且还需要进行内存映射，但是线程开销较小，仅设计到寄存器/栈的切换。进程之间的通信有很多 -- 管道、消息队列、共享内存、信号量、套接字。而线程之间的通信 -- 共享内存、条件变量和互斥锁、读写锁  

- 每个线程含有自己的寄存器和局部内存（栈），每个线程块有个共享内存，线程的切换必须保存所有的寄存器，寄存器是CPU组件，栈是内存组件，RSP寄存器指向栈顶

- 查询具有TLB（快表）的话能击大加速，如果没有命中则会去再页表中寻址。TLB一般在CPU缓存中，而页表一般在内存中。若查询的页表映射关系发生变化还可能发生缺页中断（所查找的资源由于其他资源需要进行了内存交换）

- 内存交换是不同进程之间，一般发生在内存不足的情况下，当被交换的内存被再次访问时就会触发缺页中断，然后又将该内存加载回来。内存覆盖是同一个程序之间，由程序员主动设计发生

- 虚拟技术的核心是通过​​资源复用​​抽象出比物理资源更多的逻辑资源，主要分为时分复用（CPU的时间片交替运行）和空分复用（多个进程使用不同的逻辑资源）

- 进程同步可以通过互斥锁、信号量、读写锁等进行同步
<img width="884" height="247" alt="image" src="https://github.com/user-attachments/assets/3370187f-a11d-4717-ada6-ddcf3250769c" />

- 读写锁 -- 允许多个线程并发读取，但只允许一个线程写，写的时候其余等待； 互斥锁 -- 同一时刻只能一个线程访问； 条件变量 -- 用于线程间的等待与通知，通常和互斥锁一起使用，实现线程间的同步； 自旋锁 -- 线程在尝试获取锁时不会被阻塞，而是持续循环尝试获取锁，适用于锁持有时间短且争用不严重的场景。

- 32和64位主要是cpu一次能处理的数据最大位宽，分别是四比特和八比特

- 处理速度的顺序：寄存器 -> 缓存 (数据缓存和指令缓存一般分开)-> 内存 -> 硬盘，栈是存储在内存中的，所以栈是不能快过寄存器的，也不能快过缓存（L1 L2 L3）   
- cache的单元是cache_line，CPU从内存读取数据并不是直接读，而是一块一块地放入cache中，再读取。因此提升程序运行速度可以从提升指令缓存速度和提升数据缓存速度出发

- CPU缓存的写操作有写直达和写回两个操作，写回是比较快的操作，因为它会通过标记cache里面的是否为脏数据从而进行处理，而写直达就是数据发生改动则立马进行写入

- 由于数据可能存在于多个缓存中（副本不同），因此需要控制数据的一致性问题 -- MESI（一致性协议）（实现了写传播（对任意缓存中的数据进行修改都会进行写的传播）与串行化（串行执行所有操作））
<img width="780" height="362" alt="image" src="https://github.com/user-attachments/assets/60835dca-08d1-4453-8c69-c6d0da24d8c1" />

- L1和L2是CPU核的私有缓存，L3是共享缓存。如果缓存策略是写回策略，那就是写入L1 和 L2的同时标记为脏数据，后面再更新给L3和内存，但是如果是写直达，那就是直接更新给L3，多核如果同时修改L3则会发生一致性协议的修改

- 中断分为硬中断和软中断。硬中断是由硬件设备所发出的必须立马执行的中断，软中断则是程序或操作系统内核所发出可延迟处理的中断，软中断的出现说明了资源占用情况，可以通过分析软中断在不同程序阶段出现的比例从而分析出程序的性能

- 内核架构分为宏内核，微内核和混合内核，linux采用的是宏内核，意思就是说内核的操作权限更大，windows采用的是混合内核
<img width="971" height="182" alt="image" src="https://github.com/user-attachments/assets/8faf9668-f896-4f68-8e84-2397c1d37db9" />

- 内存分段是基于代码的作用区进行分段，会产生很多内存碎片（属于外部碎片）（随着程序的执行，内存中的空闲区域可能会变得零散），有内存碎片就需要进行内存交换以合并碎片，这样的效率就会很低。内存分页是指虚拟地址和实际地址通过页进行映射，一个程序运行会使用多个整页，会产生内部碎片

- 虚拟内存虽然和物理内存是一一对应的关系，但是并不是所有的虚拟内存都会分配物理内存，只有进程所需要的时候才会进行分配，且还有内存回收的机制，因此虚拟内存一般都是大于物理内存的

- 内存不够时会触发内存回收，直接内存回收（同步），后台内存回收（异步），也可以分为文件页（文件页指的是由操作系统的内核缓存的磁盘数据或文件数据）回收（干净页直接释放）和匿名页（匿名页指的是没有实际文件载体的内存区域，通常用于堆、栈、共享内存等）回收（触发swap机制）
<img width="963" height="215" alt="image" src="https://github.com/user-attachments/assets/b3504a43-0a0a-458d-9d40-769cbd93c5c6" />

- QEMU（Quick Emulator）是一个开源的​​硬件虚拟化平台​​，允许在宿主机系统上模拟完整的虚拟计算机（包括CPU、内存、外设等）

- fork调用一次是返回两次，对于父进程是返回子进程的pid，对于子进程是返回0。fork的子进程的描述符会继承父进程的

- exec函数是将当前进程的代码、数据、堆栈等所有内存区域都替换成新的内容，从而实现进程的替换。用于加载新的可执行文件

- IO重定向原理 -- fork() + close() + open() + exec() ；文件偏移共（共享当前指针位置）享原理 -- fork() + dup()  （dup() 的作用是创建一个新的文件描述符，这个新的文件描述符和原来的文件描述符指向相同的文件，并共享文件偏移量，如果不用dup，那么就是两个进程一模一样）
<img width="960" height="220" alt="image" src="https://github.com/user-attachments/assets/8203c11f-e9ee-4de7-a443-8d17d578dd2e" />

- 内核态和用户态虽然处于同一个物理地址空间，但是其虚拟空间地址是完全分开的。线程的切换涉及到寄存器，计算器，栈顶指针，状态等切换。而进程的切换不仅设计以上，还有关于页表的切换（简称上下文的切换）

- 操作系统就是用来隔离硬件和程序的，如果没有操作系统的话，那么就不存在进程的区别，那么都作用于同一片内存，就会容易发生覆盖。操作系统内核会完成不同进程在CPU上的切换

- 操作系统启动过程：从 PC 开机到加载 Boot Loader，再到加载内核并开始运行。进程创建过程：通过分配内存、设置页表、加载程序等步骤创建一个新的进程，最终将其状态设置为就绪，等待调度。进程运行过程：调度器选择一个就绪进程并切换到内核上下文，通过 forkret 初始化新进程，最后通过 trapret 切换到用户态，开始执行用户程序。  因此进程分为运行态、就绪态和阻塞态
进入系统：PC 开机 → 加载 boot loader → boot loader 加载 xv6 内核 → 内核开始运行 ； 创建一个进程： 建页表 → 分内存 → 映射地址 → 拷程序 → 设寄存器（计数器，栈顶指针等） → 就绪调度 ； 运行一个进程： 进入调度器 → 找到 RUNNABLE 进程 → 切换到内核线程上下文 → forkret 初始化 → trapret 切换到用户态

- 进程的运行： （）二进制文件加载至代码段 → 加载数据（已初始化的在data，未初始化的在BBS） → 申请的堆栈等
代码的运行：编译期（将源代码转换成机器语言）→ 预处理期（处理一些宏定义以及include） → 链接期（动态链接和静态链接） → 运行期
<img width="930" height="317" alt="image" src="https://github.com/user-attachments/assets/29e4afe9-c0ff-4d74-9fd4-7c7dedffe653" />
<img width="226" height="417" alt="image" src="https://github.com/user-attachments/assets/4453a56b-d7c2-47e9-a735-2e13fc6fa605" />

- 线程的运行存在优先级，这个一般是task_struct（这个一般是用于存储切换上下文的地方，存储线程的优先级、结构体、寄存器啥的）进行调度。线程优先级别反转一般出现在调度的优先级和资源优先的互斥条件。线程发生自旋锁（一般是高级线程会发生）的条件（锁状态=被占用、预期等待时间<线程切换开销、优先级允许持续占用CPU）； 然而线程优先级别较低的话就会阻塞，也有可能发生优先级反转 -- 不愿意发生的事情，这就需要设计到优先级继承进行规避。线程死锁的本质是一个线程在持有资源1的情况还要继续去等待资源2的释放，可以使用有序分配法、避免占有且等待、超时机制等方法来防止死锁的发生
<img width="994" height="240" alt="image" src="https://github.com/user-attachments/assets/9f57c29b-a326-4b56-8866-ffc59e4f8a7d" />

- 锁按照类型可以分为悲观锁和乐观锁，按照阻塞方式分为自旋锁和互斥锁，按照访问权限分为读写锁和独占锁
<img width="659" height="399" alt="image" src="https://github.com/user-attachments/assets/7212d055-3855-444d-a332-7200c62277d6" />

- 并发是CPU在不同时间片上交替运行不同的进程，并行则是CPU多核在同一时间运行不同程序

- 现在的计算机普遍采用NUMA架构进行物理内存架构的设计。NUMA - 将内存划分为多个节点，每个CPU有自己的节点，优点是单个访问速度快，缺点是内存不足时若需要跨节点访问则访问延迟增加； 非NUMA则就是一根共享总线，缺点显而易见的是带宽和延迟
<img width="998" height="299" alt="image" src="https://github.com/user-attachments/assets/bf910a05-e7e2-4d65-88f2-987b7cb9dc79" />

- 每个线程都有自己的栈空间大小，因此对于有限虚拟空间内存的系统来说，其能创建的线程个数是有限的。
最大线程数 ≈ (可用虚拟地址空间 - 主线程栈 - 共享库 - 堆) / 每个线程栈大小

- 进程写文件的时候若发生崩溃是不会发生丢失的，因为会有页缓存，页缓存会自己根据选择写入磁盘，要么是强制执行，要么是根据脏数据的比例作为阈值。和CPU的MESI差不多，也是大部分写入程序都有的标准

- 零拷贝的核心目标是减少内核空间和用户空间之间的数据复制，从而减轻 CPU 的负担。有mmap + write（通过虚拟内存映射从而实现传递过程的减少 - 少了用户缓冲）和 sendfile（资源直接进入缓冲区 - 资源直接进内核缓冲区）两种方式（零拷贝），其中DMA是用于接替CPU只会IO工作的。
<img width="954" height="99" alt="image" src="https://github.com/user-attachments/assets/eaa84b10-f9ea-4b97-9846-6f3999aa8735" />
<img width="528" height="101" alt="image" src="https://github.com/user-attachments/assets/d080bcac-1dfb-45a5-b729-0ebe220e2208" />
<img width="1155" height="436" alt="image" src="https://github.com/user-attachments/assets/e4c12ec1-83f4-45bc-b1c7-3397dc30d16a" />

- 一般任务的分类都是分为IO密集形和CPU密集型，这两个任务代表的优化方案不同，IO密集型就是可以利用异步IO实现优化，缺点就是设计复杂。当并发连接数非常大时，select 和 poll 会面临性能瓶颈。epoll 改进了这一点，但在极端情况下，仍然可能产生开销。

- select poll和epoll本质上就是linux系统中用于同时监控多个文件描述符的方法，简称多路复用机制，select 与 poll是需要轮询所有的fd，而epoll是事件驱动型，只有fd传入了才开始进行读取

- 一致哈希环是通过红黑树实现的，它的存在是用于实现传统哈希增加或者减少节点从而导致的整个哈希进行重分布的问题，它只会改变哈希“环”的一小部分。

- 线程的结束分为正常终止（main函数正常退出、exit显式退出）与异常终止（使用kill、程序发生错误（段错误等）、调用abort），可以根据状态码进行区分，正常终止的状态码一般是0或者自定义的数值，而异常终止是128 + 状态码

- 协程是类似于更加轻量化的进程，本质都是用于处理io密集型任务，进程的异步io是有回调函数，而协程的异步io是同步函数。协程是由用户控制的一种非抢占式的，而线程是内核态调度的抢占式。

- 回调多了会产生“回调地狱”，因为每多一个回调就会多一次循环，整体代码向右生长。而同步就是整齐排列

- 匿名页 - 存储进程运行时动态分配的数据（如堆、栈、共享内存等）； 文件页 - 缓存磁盘文件内容（如程序代码、内存映射文件mmap）。匿名页通过swap进行交换回收，而文件页的回收就是有主动回收和强制回收那些。这些都是在内存里面，匿名页利用swap后可以存储在磁盘里面，文件页也有手段存储到磁盘。运行机理就是RPC。（页表不是同一个概念，页表是由MMU控制）

- MMU是用于将虚拟内存映射到物理内存的，实际被映射的物理地址可以是不连续的，因此MMU有效地解决了外部碎片的问题，但是依旧没有解决内部碎片的问题，因此就有了伙伴系统的出现，伙伴系统就是会将内存分成2的幂次方，需要用的话就拆开，不需要用的话就合并

- malloc分配的内容是未初始化的，底层实现就是brk和mmap；calloc分配后是初始化为0的，也是通过brk和mmap，只不过分配后会清零内存；realloc是保留原数据并支持内存扩展，确实是存在和哈希扩容存在的问题，有性能风险。（栈也是用的mmap，mmap创建的内存是具有隔离性的，而brk只是顶端指针调用）

- 匿名页主要是用于临时的，私有的内存，文件页是用于持久化的共享得文件

- volatile本质就是产生内存屏障（特殊的机器指令），具体修饰的变量每次都会重新从内存中读取，禁止从缓存中读，防止程序优化

- sbrk是通过增量返回旧地址，brk是返回新地址，通常用于动态内存分配。sbrk是brk的上层封装
